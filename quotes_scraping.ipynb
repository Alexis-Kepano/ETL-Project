{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pymongo\n",
    "\n",
    "# Setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.driver.maximize_window()\n",
    "\n",
    "# URL of page to be scraped\n",
    "url_base = \"http://quotes.toscrape.com/\"\n",
    "next_page_link=''\n",
    "\n",
    "quote_everything=[] #collection of everything associated with the quotes\n",
    "quote_list=[] #collection of quotes\n",
    "author_info=[] #collection of author information\n",
    "tag_relation=[] #collection for tag and quote relation\n",
    "unique_tags=[] #stores unique tags\n",
    "tags=[]#used to store a collection of tags\n",
    "\n",
    "while True:\n",
    "    url=url_base+next_page_link\n",
    "    browser.visit(url)\n",
    "    html=browser.html\n",
    "    quote_soup=BeautifulSoup(html,'html.parser')\n",
    "    quotes=quote_soup.find_all('div',class_='quote')\n",
    "    #loops each quote on the web page quotes.toscrape.com\n",
    "    \n",
    "\n",
    "    for quote in quotes:\n",
    "        #finds the quote text\n",
    "        q_text = quote.find('span',class_=\"text\").text\n",
    "        #print(q_text)\n",
    "        #finds all tags \n",
    "        q_tags = quote.find_all('a',class_=\"tag\")\n",
    "\n",
    "        #list to store all tags\n",
    "        tag_list=[]\n",
    "        #loops through the quote tags and adds it to tag list\n",
    "        for tag in q_tags:\n",
    "            for t in tag:\n",
    "                if t not in unique_tags:\n",
    "                    unique_tags.append(t)\n",
    "                    tags.append({\"tag\":t})\n",
    "                    \n",
    "            tag_text=tag.text\n",
    "            tag_list.append(tag_text)\n",
    "        \n",
    "        #visiting author page\n",
    "        #get author link\n",
    "        try:\n",
    "            #get link to author's page\n",
    "            author_link = quote.find('a')['href']\n",
    "            #print(author_link)\n",
    "            #got to author's page\n",
    "            browser.visit(url_base+author_link)\n",
    "#           time.sleep(10)\n",
    "            html2=browser.html\n",
    "            #get the html soup from author_link\n",
    "            author_soup=BeautifulSoup(html2,'html.parser')\n",
    "            #get author_details from author_soup\n",
    "            author_details=author_soup.find('div',class_='author-details')\n",
    "            #get author's name from author_details\n",
    "            author_name = author_details.find('h3').text\n",
    "            #get author's birth date and place from author_details \n",
    "            author_born=author_details.find('span',class_='author-born-date').text + \" \"+ author_details.find('span',class_='author-born-location').text\n",
    "            #get the description of the author\n",
    "            author_description=author_details.find('div',class_=\"author-description\").text\n",
    "            #creates a dictionary for quote, tag, author's name, born, and description \n",
    "            quote_everything_dict={\"quote_text\":q_text,\"tags\":tag_list,\"author_name\":author_name,\"author_born\":author_born,\"author_description\":author_description}\n",
    "            quote_dict={\"quote_text\":q_text,\"author_name\":author_name}\n",
    "            author_info_dict={\"name\":author_name,\"born\":author_born,\"description\":author_description}\n",
    "           \n",
    "            tags_dict={\"quote_text\":q_text,\"tag\":tag_list}\n",
    "            #stores dictionaries in a quote_list, author_info, tag_relation\n",
    "            quote_list.append(quote_dict)\n",
    "            author_info.append(author_info_dict)\n",
    "            quote_everything.append(quote_everything_dict)\n",
    "            tag_relation.append(tags_dict)\n",
    "            browser.back()\n",
    "        except Exception as e:\n",
    "            print(\"Scraping Author Page Complete\")\n",
    "            break\n",
    "            \n",
    "        \n",
    "            \n",
    "    try:\n",
    "        next_page = quote_soup.find('li',class_='next')\n",
    "        next_page_link = next_page.find('a')['href']\n",
    "        #browser.close()\n",
    "        #print(next_page_link)\n",
    "    except Exception as e:\n",
    "        print(f\"Scraping Quotes Page Complete\")\n",
    "        break\n",
    "        \n",
    "browser.quit()  \n",
    "pprint(len(quote_list))\n",
    "\n",
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "#creates a data base quotes_db\n",
    "db=client.quotes_db\n",
    "#creates a collections for database quotes_db\n",
    "db.quotes.drop()\n",
    "db.quotes_everything_collection.drop()\n",
    "db.quotes_collection.drop()\n",
    "db.author_information_collection.drop()\n",
    "db.tag_relation_collection.drop()\n",
    "db.tags_collection.drop()\n",
    "#-------------------------------------------------------\n",
    "#insert collections as a MongoDB document\n",
    "collection_1 = db.quotes_everything_collection\n",
    "collection_2=db.quotes_collection\n",
    "collection_3=db.author_information_collection\n",
    "collection_4=db.tag_relation_collection\n",
    "collection_5 = db.tags_collection\n",
    "collection_1.insert_many(quote_everything)\n",
    "collection_2.insert_many(quote_list)\n",
    "collection_3.insert_many(author_info)\n",
    "collection_4.insert_many(tag_relation)\n",
    "collection_5.insert_many(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
